{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee680326",
   "metadata": {},
   "source": [
    "## NeuroDet: split data by classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b06600",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6730f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers.TimeDistributed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d1/rr73p9ls7klcgxky01n9171m0000gn/T/ipykernel_22462/1109848771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.TimeDistributed'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "# Disabling GPU for the moment because of the lack of the memory\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3727d09",
   "metadata": {},
   "source": [
    "### Loading the dataset of Brain Scan images\n",
    "#### Full data for training and testing\n",
    "Source of the Dataset: [Kaggle-Brain Tumor Classification](https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri?select=Testing)<br>\n",
    "Reference for operations performed : [Tensorflow tutorial: Load Images](https://www.tensorflow.org/tutorials/load_data/images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb78c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train examples: 2870\n",
      "Total number of test examples: 394\n",
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "train_data_full len = 1\n",
      "test_data_full len = 1\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 21:17:28.331009: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "categories_path = {'glioma_tumor': '/glioma_tumor', 'meningioma_tumor': '/meningioma_tumor', \n",
    "                   'pituitary_tumor': '/pituitary_tumor', 'no_tumor':'/no_tumor'}\n",
    "train_path = 'BrainMRI/Training'\n",
    "test_path = 'BrainMRI/Testing'\n",
    "\n",
    "# train_glioma_dir = pathlib.Path(train_path + categories_path['glioma_tumor'])\n",
    "train_dir = pathlib.Path(train_path)\n",
    "test_dir = pathlib.Path(test_path)\n",
    "\n",
    "# Training data: number of examples\n",
    "# label = 0 | glioma_tumor: 826\n",
    "# label = 1 | meningioma_tumor: 822\n",
    "# label = 2 | no_tumor: 395 \n",
    "# label = 3 | pituitary_tumor: 827 \n",
    "\n",
    "# Testing data: number of examples\n",
    "# label = 0 | glioma_tumor: 100\n",
    "# label = 1 | meningioma_tumor: 115\n",
    "# label = 2 | no_tumor: 105\n",
    "# label = 3 | pituitary_tumor: 74\n",
    "\n",
    "num_train_examples_dict = {\n",
    "    \"label_0\": 826, \"label_1\": 822, \"label_2\": 395, \"label_3\": 827}\n",
    "\n",
    "num_test_examples_dict = {\n",
    "    \"label_0\": 100, \"label_1\": 115, \"label_2\": 105, \"label_3\": 74}\n",
    "\n",
    "\n",
    "num_train_examples = sum(num_train_examples_dict.values()) # 2870\n",
    "num_test_examples = sum(num_test_examples_dict.values()) # 394\n",
    "\n",
    "print(f'Total number of train examples: {num_train_examples}')\n",
    "print(f'Total number of test examples: {num_test_examples}') \n",
    "\n",
    "# Defining the parameters of the dataset\n",
    "batch_size = 128\n",
    "img_height = 256 # was 128\n",
    "img_width = 256 # was 128\n",
    "\n",
    "\n",
    "\n",
    "# Loading the train dataset using keras.utils.image_dataset_from_directory\n",
    "# To use this method, please ensure you have tf.nigthly installed \n",
    "train_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_train_examples, \n",
    "    shuffle=True,\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "test_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_test_examples, \n",
    "    shuffle=True,\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "print(f'train_data_full len = {len(train_data_full)}') # 1 batch = full dataset\n",
    "print(f'test_data_full len = {len(test_data_full)}') # 1 batch = full dataset\n",
    "print(train_data_full.class_names)\n",
    "print(test_data_full.class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278c301",
   "metadata": {},
   "source": [
    "### Normalizing the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0fc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_data_full = train_data_full.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_data_full = test_data_full.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# FYI: will print error b/c you can't print class_names after normalizing with .map\n",
    "# print(train_ds.class_names) \n",
    "# print(test_ds.class_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be3160",
   "metadata": {},
   "source": [
    "### Function to split data by classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "680d58d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_images_0) = 826, len(train_labels_0) = 826\n",
      "len(train_images_1) = 822, len(train_labels_1) = 822\n",
      "len(train_images_2) = 395, len(train_labels_2) = 395\n",
      "len(train_images_3) = 827, len(train_labels_3) = 827\n",
      "len(test_images_0) = 100, len(test_labels_0) = 100\n",
      "len(test_images_1) = 115, len(test_labels_1) = 115\n",
      "len(test_images_2) = 105, len(test_labels_2) = 105\n",
      "len(test_images_3) = 74, len(test_labels_3) = 74\n"
     ]
    }
   ],
   "source": [
    "def split_data_classes(dataset):\n",
    "    images_0 = []; labels_0 = []\n",
    "    images_1 = []; labels_1 = []\n",
    "    images_2 = []; labels_2 = []\n",
    "    images_3 = []; labels_3 = []\n",
    "    # OR can do:\n",
    "    # for batch_images, batch_labels in train_ds_unbatched: \n",
    "    #    print(f'batch_images = {batch_images.shape}') # (2870, 256, 256, 1)\n",
    "    #    print(f'batch_labels = {batch_labels.shape}') # (2870,)\n",
    "    # for i in range(len(batch_labels): ...\n",
    "\n",
    "    for batch_data in dataset: \n",
    "        batch_images = batch_data[0]\n",
    "        batch_labels = batch_data[1]\n",
    "    \n",
    "        for i in range(len(batch_labels)):\n",
    "            if batch_labels[i] == 0:\n",
    "                images_0.append(batch_images[i])\n",
    "                labels_0.append(batch_labels[i])\n",
    "            elif batch_labels[i] == 1:\n",
    "                images_1.append(batch_images[i])\n",
    "                labels_1.append(batch_labels[i])\n",
    "            elif batch_labels[i] == 2:\n",
    "                images_2.append(batch_images[i])\n",
    "                labels_2.append(batch_labels[i]) \n",
    "            else: # batch_labels[i] == 3:\n",
    "                images_3.append(batch_images[i])\n",
    "                labels_3.append(batch_labels[i])\n",
    "    return [images_0, images_1, images_2, images_3, labels_0, labels_1, labels_2, labels_3]\n",
    "\n",
    "# train_images_0, train_images_1, train_images_2, train_images_3, train_labels_0, train_labels_1, train_labels_2, labels_3 = \n",
    "train_data_classes = split_data_classes(dataset=train_ds_unbatched) \n",
    "train_images_0 = train_data_classes[0]; train_labels_0 = train_data_classes[4]\n",
    "train_images_1 = train_data_classes[1]; train_labels_1 = train_data_classes[5]\n",
    "train_images_2 = train_data_classes[2]; train_labels_2 = train_data_classes[6]\n",
    "train_images_3 = train_data_classes[3]; train_labels_3 = train_data_classes[7]\n",
    "\n",
    "# print(train_images_0) # tf of 826 images of shape=(256, 256, 1)\n",
    "# print(train_labels_1) # tf.Tensor of dtype=int32, all values of 0\n",
    "print(f'len(train_images_0) = {len(train_images_0)}, len(train_labels_0) = {len(train_labels_0)}') # 826\n",
    "print(f'len(train_images_1) = {len(train_images_1)}, len(train_labels_1) = {len(train_labels_1)}') # 822\n",
    "print(f'len(train_images_2) = {len(train_images_2)}, len(train_labels_2) = {len(train_labels_2)}') # 395\n",
    "print(f'len(train_images_3) = {len(train_images_3)}, len(train_labels_3) = {len(train_labels_3)}') # 827\n",
    "# 826 + 822 + 395 + 827 = 2870\n",
    "\n",
    "test_data_classes = split_data_classes(dataset=test_ds_unbatched)\n",
    "test_images_0 = test_data_classes[0]; test_labels_0 = test_data_classes[4]\n",
    "test_images_1 = test_data_classes[1]; test_labels_1 = test_data_classes[5]\n",
    "test_images_2 = test_data_classes[2]; test_labels_2 = test_data_classes[6]\n",
    "test_images_3 = test_data_classes[3]; test_labels_3 = test_data_classes[7]\n",
    "\n",
    "print(f'len(test_images_0) = {len(test_images_0)}, len(test_labels_0) = {len(test_labels_0)}') # 100\n",
    "print(f'len(test_images_1) = {len(test_images_1)}, len(test_labels_1) = {len(test_labels_1)}') # 115\n",
    "print(f'len(test_images_2) = {len(test_images_2)}, len(test_labels_2) = {len(test_labels_2)}') # 105\n",
    "print(f'len(test_images_3) = {len(test_images_3)}, len(test_labels_3) = {len(test_labels_3)}') # 74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3c646",
   "metadata": {},
   "source": [
    "### LSTM for full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ed79b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (2870, 256, 256, 1)\n",
      "y_train.shape = (2870,)\n",
      "x_test.shape = (394, 256, 256, 1)\n",
      "y_test.shape = (394,)\n",
      "x_train.shape[0] = 2870\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_data_full:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "for images, labels in test_data_full:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "print(f'x_train.shape = {x_train.shape}') # (2870, 256, 256, 1)\n",
    "print(f'y_train.shape = {y_train.shape}') # (2870,)\n",
    "print(f'x_test.shape = {x_test.shape}') # (394, 256, 256, 1)\n",
    "print(f'y_test.shape = {y_test.shape}') # (394,)\n",
    "\n",
    "print(f'x_train.shape[0] = {x_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1ba76be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (2848, 256, 256, 1)\n",
      "y_train.shape = (2848,)\n",
      "y_test.shape = (384, 256, 256, 1)\n",
      "y_test.shape = (384,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Subset data so that it is a multiple of batch_size\n",
    "def subset_data(data, batch_size, dataset_type):\n",
    "    data_subset_num_examples = (data.shape[0]//batch_size)*batch_size\n",
    "    if dataset_type == 'images':\n",
    "        data_subset = data[:data_subset_num_examples,:,:,:] \n",
    "    else: # dataset_type == 'labels'\n",
    "        data_subset = data[:data_subset_num_examples,]       \n",
    "    return data_subset\n",
    "\n",
    "x_train = subset_data(x_train, train_batch_size,'images')\n",
    "print(f'x_train.shape = {x_train.shape}')\n",
    "\n",
    "y_train = subset_data(y_train, train_batch_size, 'labels')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "\n",
    "x_test = subset_data(x_test, train_batch_size, 'images')\n",
    "print(f'y_test.shape = {x_test.shape}')\n",
    "y_test = subset_data(y_test, train_batch_size, 'labels')\n",
    "print(f'y_test.shape = {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2b9c2274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2848, 256, 256, 1)\n",
      "(2848, 256, 256, 1)\n",
      "(2848,)\n",
      "(2848,)\n"
     ]
    }
   ],
   "source": [
    "# Subset x_train so that it is a multiple of batch_size\n",
    "x_train_subset_n = (x_train.shape[0]//batch_size)*batch_size\n",
    "x_train_subset = x_train[:x_train_subset_n,:,:,:]\n",
    "print(x_train_subset.shape)\n",
    "x_train = x_train_subset\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "# Subset y_train so that it is a multiple of batch_size\n",
    "y_train_subset_n = (y_train.shape[0]//batch_size)*batch_size\n",
    "y_train_subset = y_train[:y_train_subset_n,]\n",
    "print(y_train_subset.shape)\n",
    "\n",
    "y_train = y_train_subset\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897565ea",
   "metadata": {},
   "source": [
    "## 2 LSTM layers, 1 Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "573c01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(32, 256, 256)]          0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (32, 256, 128)            197120    \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (32, 128)                 131584    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (32, 10)                  1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329,994\n",
      "Trainable params: 329,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 20s 194ms/step - loss: 1.4126 - accuracy: 0.2805\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.3644 - accuracy: 0.2866\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.3633 - accuracy: 0.2805\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 19s 214ms/step - loss: 1.3632 - accuracy: 0.2873\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 19s 217ms/step - loss: 1.3589 - accuracy: 0.2770\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 1.3581 - accuracy: 0.2848\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.3532 - accuracy: 0.2933\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 1.3537 - accuracy: 0.2947\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 17s 190ms/step - loss: 1.3509 - accuracy: 0.2681\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.3545 - accuracy: 0.2979\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 1.4189 - accuracy: 0.2969\n",
      "Testing loss = 1.4188861846923828, Testing accuracy = 0.296875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tf.keras.layers.Input(batch_input_shape=(batch_size,256,256))\n",
    "\n",
    "lstm_size = 128\n",
    "num_epochs = 10 #50 # 5\n",
    "learning_rate = 0.005\n",
    "dense1_size = 10\n",
    "\n",
    "lstm1_output = tf.keras.layers.LSTM(lstm_size, return_sequences=True)(inputs)\n",
    "lstm2_output = tf.keras.layers.LSTM(lstm_size)(lstm1_output)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(dense1_size, activation='softmax')(lstm2_output)\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    tf.squeeze(x_train), \n",
    "    tf.squeeze(y_train), \n",
    "    epochs=num_epochs, \n",
    "    # shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387abbf",
   "metadata": {},
   "source": [
    "## 1 LSTM layer, 1 Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4392dea6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(32, 256, 256)]          0         \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (32, 128)                 197120    \n",
      "                                                                 \n",
      " dense_33 (Dense)            (32, 10)                  1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,410\n",
      "Trainable params: 198,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "89/89 [==============================] - 10s 95ms/step - loss: 1.4022 - accuracy: 0.2872\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.3614 - accuracy: 0.2823\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 1.3572 - accuracy: 0.2928\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.3477 - accuracy: 0.2886\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.3434 - accuracy: 0.3055\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 1.3353 - accuracy: 0.3002\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.3366 - accuracy: 0.3083\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.3278 - accuracy: 0.3086\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.3202 - accuracy: 0.3392\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.2898 - accuracy: 0.3248\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.3275 - accuracy: 0.3297\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.3204 - accuracy: 0.3027\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.3118 - accuracy: 0.3279\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.2948 - accuracy: 0.3476\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.2155 - accuracy: 0.4526\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.2999 - accuracy: 0.3627\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.3291 - accuracy: 0.3114\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.2872 - accuracy: 0.3796\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.2265 - accuracy: 0.4438\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.2025 - accuracy: 0.4702\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.1788 - accuracy: 0.4796\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.1441 - accuracy: 0.5035\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.1211 - accuracy: 0.5039\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.1307 - accuracy: 0.4979\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.0831 - accuracy: 0.5242\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.0511 - accuracy: 0.5478\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 9s 101ms/step - loss: 1.0130 - accuracy: 0.5558\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 1.0183 - accuracy: 0.5495\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9889 - accuracy: 0.5590\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9367 - accuracy: 0.5930\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9544 - accuracy: 0.5751\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9393 - accuracy: 0.5822\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9260 - accuracy: 0.6032\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9053 - accuracy: 0.5980\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.0291 - accuracy: 0.5558\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.9404 - accuracy: 0.6057\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.0987 - accuracy: 0.5151\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.9880 - accuracy: 0.5629\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9491 - accuracy: 0.5832\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.9515 - accuracy: 0.5829\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.9578 - accuracy: 0.5938\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9401 - accuracy: 0.5885\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9843 - accuracy: 0.5727\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9046 - accuracy: 0.6138\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9250 - accuracy: 0.5945\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8773 - accuracy: 0.6289\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9134 - accuracy: 0.6152\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9458 - accuracy: 0.5874\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.9547 - accuracy: 0.5969\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 1.0678 - accuracy: 0.5414\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.9359 - accuracy: 0.5853\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8798 - accuracy: 0.6067\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8634 - accuracy: 0.6204\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.8456 - accuracy: 0.6369\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.8276 - accuracy: 0.6447\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8458 - accuracy: 0.6275\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.8042 - accuracy: 0.6485\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8257 - accuracy: 0.6313\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 0.9861 - accuracy: 0.5762\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 10s 110ms/step - loss: 0.8286 - accuracy: 0.6422\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.8173 - accuracy: 0.6422\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.8338 - accuracy: 0.6433\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.8082 - accuracy: 0.6555\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.8126 - accuracy: 0.6503\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 0.7893 - accuracy: 0.6608\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 9s 101ms/step - loss: 0.7790 - accuracy: 0.6710\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 11s 118ms/step - loss: 0.7714 - accuracy: 0.6682\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 0.7503 - accuracy: 0.6780\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.7483 - accuracy: 0.6692\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 0.7402 - accuracy: 0.6805\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 10s 111ms/step - loss: 0.7386 - accuracy: 0.6815\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 0.7702 - accuracy: 0.6752\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 10s 115ms/step - loss: 0.7426 - accuracy: 0.6871\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 9s 106ms/step - loss: 0.7234 - accuracy: 0.6935\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 0.7178 - accuracy: 0.7008\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 0.6991 - accuracy: 0.7107\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 10s 112ms/step - loss: 0.7057 - accuracy: 0.6963\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 0.6949 - accuracy: 0.7065\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 10s 115ms/step - loss: 0.7053 - accuracy: 0.6991\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 0.8701 - accuracy: 0.6327\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 0.9544 - accuracy: 0.5885\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 10s 117ms/step - loss: 0.8756 - accuracy: 0.6447\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 10s 110ms/step - loss: 0.8345 - accuracy: 0.6485\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 0.8070 - accuracy: 0.6675\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 0.7959 - accuracy: 0.6710\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 0.7726 - accuracy: 0.6787\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 9s 101ms/step - loss: 0.7673 - accuracy: 0.6798\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 0.7434 - accuracy: 0.6910\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 0.7372 - accuracy: 0.6931\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 10s 107ms/step - loss: 0.7314 - accuracy: 0.7026\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.7360 - accuracy: 0.6836\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.7188 - accuracy: 0.6956\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 0.7248 - accuracy: 0.6889\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 0.6968 - accuracy: 0.7152\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 0.7235 - accuracy: 0.6935\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 0.7155 - accuracy: 0.6921\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 11s 126ms/step - loss: 0.6799 - accuracy: 0.7131\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 11s 127ms/step - loss: 0.6823 - accuracy: 0.7170\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 0.6733 - accuracy: 0.7152\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 0.6879 - accuracy: 0.7142\n",
      "12/12 [==============================] - 1s 38ms/step - loss: 2.3287 - accuracy: 0.2995\n",
      "Testing loss = 2.328716278076172, Testing accuracy = 0.2994791567325592\n"
     ]
    }
   ],
   "source": [
    "#inputs = tf.keras.layers.Input(batch_input_shape=(None,256,256))\n",
    "inputs = tf.keras.layers.Input(batch_input_shape=(batch_size,256,256))\n",
    "\n",
    "# num_epochs = 10\n",
    "# s 10:35 - <11:10\n",
    "# x = tf.keras.layers.LSTM(512)(inputs)\n",
    "# Epoch 10/10\n",
    "# 90/90 [==============================] - 179s 2s/step - loss: 0.4806 - acc: 0.7993\n",
    "# 13/13 [==============================] - 19s 1s/step - loss: 1.9995 - acc: 0.4137\n",
    "# Testing loss = 1.9995168447494507, Testing accuracy = 0.41370558738708496\n",
    "\n",
    "# x = tf.keras.layers.LSTM(128)(inputs)\n",
    "# 0.5636 - acc: 0.7666, 10 epochs, \n",
    "# Testing loss = 1.8103610277175903, Testing accuracy = 0.3832487165927887\n",
    "\n",
    "# 3:04 start\n",
    "lstm_size = 128\n",
    "num_epochs = 100 #50 # 5\n",
    "learning_rate = 0.008\n",
    "dense1_size = 10\n",
    "\n",
    "lstm_output = tf.keras.layers.LSTM(lstm_size)(inputs)\n",
    "\n",
    "# Epoch 50/50\n",
    "# 90/90 [==============================] - 10s 114ms/step - loss: 0.0911 - acc: 0.9683\n",
    "# 13/13 [==============================] - 1s 38ms/step - loss: 2.2423 - acc: 0.6827\n",
    "# Testing loss = 2.2423360347747803, Testing accuracy = 0.682741105556488\n",
    "\n",
    "\n",
    "#outputs = tf.keras.layers.Dense(train_batch_size, activation='softmax')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(dense1_size, activation='softmax')(lstm_output)\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    tf.squeeze(x_train), \n",
    "    tf.squeeze(y_train), \n",
    "    epochs=num_epochs, \n",
    "    # shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c1175",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "02f45468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,410\n",
      "Trainable params: 198,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "90/90 [==============================] - 12s 111ms/step - loss: 1.4797 - accuracy: 0.2669\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 1.3611 - accuracy: 0.2864\n",
      "Epoch 3/50\n",
      "67/90 [=====================>........] - ETA: 2s - loss: 1.3575 - accuracy: 0.2766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d1/rr73p9ls7klcgxky01n9171m0000gn/T/ipykernel_7255/3525599599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     epochs=num_epochs)\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# shuffle=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#batch_size=batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 _r=1):\n\u001b[1;32m   1308\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for images, labels in train_data_full:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "for images, labels in test_data_full:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "\n",
    "lstm_size = 128\n",
    "num_epochs = 50 # 5\n",
    "learning_rate = 0.001\n",
    "dense1_size = 10\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(batch_input_shape=(None,256,256)))\n",
    "model.add(tf.keras.layers.LSTM(lstm_size))\n",
    "model.add(tf.keras.layers.Dense(dense1_size, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    # optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    tf.squeeze(x_train), \n",
    "    tf.squeeze(y_train), \n",
    "    epochs=num_epochs)\n",
    "    # shuffle=True,\n",
    "    #batch_size=batch_size)\n",
    "\n",
    "# test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3294e",
   "metadata": {},
   "source": [
    "## LSTM works best - idk why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8256d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "train_ds_unbatched len = 1\n",
      "test_ds_unbatched len = 1\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 256, 256)]        0         \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,410\n",
      "Trainable params: 198,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "90/90 [==============================] - 11s 112ms/step - loss: 1.2023 - acc: 0.4554\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 0.9531 - acc: 0.5857\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.8426 - acc: 0.6233\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.7657 - acc: 0.6613\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.7277 - acc: 0.6861\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.6610 - acc: 0.7073\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 0.5803 - acc: 0.7516\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.5426 - acc: 0.7686\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.5065 - acc: 0.7847\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4860 - acc: 0.7944\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4476 - acc: 0.8146\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4250 - acc: 0.8261\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.4100 - acc: 0.8289\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.3964 - acc: 0.8429\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3458 - acc: 0.8641\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3318 - acc: 0.8714\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 0.3093 - acc: 0.8774\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3421 - acc: 0.8662\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.2722 - acc: 0.8944\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.2444 - acc: 0.9059\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.2299 - acc: 0.9143\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.2910 - acc: 0.8833\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.2323 - acc: 0.9122\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.2294 - acc: 0.9160\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.1963 - acc: 0.9307\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1944 - acc: 0.9265\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1856 - acc: 0.9334\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1618 - acc: 0.9411\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.2000 - acc: 0.9244\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1630 - acc: 0.9380\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1945 - acc: 0.9286\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1372 - acc: 0.9523\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1269 - acc: 0.9568\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 11s 122ms/step - loss: 0.1303 - acc: 0.9575\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1465 - acc: 0.9456\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1309 - acc: 0.9564\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 0.1417 - acc: 0.9456\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1984 - acc: 0.9324\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 11s 122ms/step - loss: 0.1507 - acc: 0.9408\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.1007 - acc: 0.9631\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1103 - acc: 0.9631\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0863 - acc: 0.9707\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 11s 123ms/step - loss: 0.0814 - acc: 0.9711\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1169 - acc: 0.9638\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 0.1138 - acc: 0.9624\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 11s 127ms/step - loss: 0.0616 - acc: 0.9777\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 11s 123ms/step - loss: 0.0536 - acc: 0.9868\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 11s 122ms/step - loss: 0.0395 - acc: 0.9889\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 0.0478 - acc: 0.9850\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 11s 121ms/step - loss: 0.0468 - acc: 0.9871\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 2.5929 - acc: 0.6954\n",
      "Testing loss = 2.592863082885742, Testing accuracy = 0.6954314708709717\n"
     ]
    }
   ],
   "source": [
    "train_ds_unbatched = tf.keras.utils.image_dataset_from_directory(train_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=2870, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "test_ds_unbatched = tf.keras.utils.image_dataset_from_directory(test_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=394, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "print(f'train_ds_unbatched len = {len(train_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(f'test_ds_unbatched len = {len(test_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(train_ds_unbatched.class_names)\n",
    "print(test_ds_unbatched.class_names)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "print(train_ds.class_names)\n",
    "print(test_ds.class_names)\n",
    "\n",
    "train_ds_unbatched = train_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds_unbatched = test_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "x_train = None; y_train = None\n",
    "for images, labels in train_ds_unbatched:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "x_test = None; y_test = None\n",
    "for images, labels in test_ds_unbatched:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "inputs = tf.keras.layers.Input(batch_input_shape=(None,256,256))\n",
    "\n",
    "\n",
    "size_lstm = 128\n",
    "num_epochs = 50\n",
    "learning_rate = 0.005\n",
    "x = tf.keras.layers.LSTM(size_lstm)(inputs)\n",
    "\n",
    "\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()\n",
    "model.compile(#optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(tf.squeeze(x_train), tf.squeeze(y_train), epochs=num_epochs)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c442aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "train_ds_unbatched len = 1\n",
      "test_ds_unbatched len = 1\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 256, 256)]        0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,410\n",
      "Trainable params: 198,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 11s 102ms/step - loss: 1.2295 - acc: 0.4272\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.9656 - acc: 0.5739\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 0.8643 - acc: 0.6317\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.7917 - acc: 0.6690\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 0.7079 - acc: 0.7167\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.6551 - acc: 0.7258\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.5940 - acc: 0.7557\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.5547 - acc: 0.7725\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.5465 - acc: 0.7718\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.4969 - acc: 0.7979\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.4513 - acc: 0.8178\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.4253 - acc: 0.8226\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.4158 - acc: 0.8293\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3764 - acc: 0.8491\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3669 - acc: 0.8467\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.3324 - acc: 0.8631\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.4058 - acc: 0.8272\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.3482 - acc: 0.8526\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3074 - acc: 0.8742\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.3029 - acc: 0.8840\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.3223 - acc: 0.8693\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.2613 - acc: 0.8993\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.2521 - acc: 0.9038\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.2426 - acc: 0.9042\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.2317 - acc: 0.9056\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.2195 - acc: 0.9192\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1916 - acc: 0.9296\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1949 - acc: 0.9289\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.2105 - acc: 0.9202\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 123ms/step - loss: 0.1720 - acc: 0.9355\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1752 - acc: 0.9380\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1768 - acc: 0.9321\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1644 - acc: 0.9394\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1668 - acc: 0.9380\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1295 - acc: 0.9571\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.1521 - acc: 0.9498\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1536 - acc: 0.9415\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1229 - acc: 0.9589\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1675 - acc: 0.9418\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1102 - acc: 0.9610\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1050 - acc: 0.9655\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1123 - acc: 0.9620\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0958 - acc: 0.9645\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1058 - acc: 0.9659\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 0.0927 - acc: 0.9693\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0853 - acc: 0.9725\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0606 - acc: 0.9815\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1010 - acc: 0.9652\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.2387 - acc: 0.9178\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1591 - acc: 0.9397\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0904 - acc: 0.9683\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0748 - acc: 0.9767\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0685 - acc: 0.9798\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0519 - acc: 0.9850\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0525 - acc: 0.9843\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0459 - acc: 0.9871\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0727 - acc: 0.9760\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.2214 - acc: 0.9265\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1593 - acc: 0.9460\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0911 - acc: 0.9679\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0612 - acc: 0.9801\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0811 - acc: 0.9721\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0803 - acc: 0.9714\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0601 - acc: 0.9819\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0445 - acc: 0.9878\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0492 - acc: 0.9857\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0637 - acc: 0.9794\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.1091 - acc: 0.9638\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1290 - acc: 0.9554\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0700 - acc: 0.9767\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0399 - acc: 0.9878\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 0.0375 - acc: 0.9885\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0462 - acc: 0.9843\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0291 - acc: 0.9913\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0227 - acc: 0.9937\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1290 - acc: 0.9599\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 0.1072 - acc: 0.9610\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.0790 - acc: 0.9735\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.0720 - acc: 0.9746\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 122ms/step - loss: 0.0456 - acc: 0.9871\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0460 - acc: 0.9875\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 123ms/step - loss: 0.0187 - acc: 0.9951\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0117 - acc: 0.9976\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0072 - acc: 0.9990\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.0129 - acc: 0.9976\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0065 - acc: 0.9986\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0050 - acc: 0.9990\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.0453 - acc: 0.9868\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 0.1845 - acc: 0.9334\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.1134 - acc: 0.9592\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 0.1286 - acc: 0.9578\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.0659 - acc: 0.9767\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 0.0241 - acc: 0.9937\n",
      "13/13 [==============================] - 1s 38ms/step - loss: 3.1560 - acc: 0.6904\n",
      "Testing loss = 3.1560451984405518, Testing accuracy = 0.6903553009033203\n"
     ]
    }
   ],
   "source": [
    "train_ds_unbatched = tf.keras.utils.image_dataset_from_directory(train_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=2870, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "test_ds_unbatched = tf.keras.utils.image_dataset_from_directory(test_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=394, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "print(f'train_ds_unbatched len = {len(train_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(f'test_ds_unbatched len = {len(test_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(train_ds_unbatched.class_names)\n",
    "print(test_ds_unbatched.class_names)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "print(train_ds.class_names)\n",
    "print(test_ds.class_names)\n",
    "\n",
    "train_ds_unbatched = train_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds_unbatched = test_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "x_train = None; y_train = None\n",
    "for images, labels in train_ds_unbatched:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "x_test = None; y_test = None\n",
    "for images, labels in test_ds_unbatched:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "inputs = tf.keras.layers.Input(batch_input_shape=(None,256,256))\n",
    "\n",
    "\n",
    "size_lstm = 128\n",
    "num_epochs = 100\n",
    "learning_rate = 0.005\n",
    "x = tf.keras.layers.LSTM(size_lstm)(inputs)\n",
    "\n",
    "\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()\n",
    "model.compile(#optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(tf.squeeze(x_train), tf.squeeze(y_train), epochs=num_epochs)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f705a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "train_ds_unbatched len = 1\n",
      "test_ds_unbatched len = 1\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256, 128)          197120    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,964\n",
      "Trainable params: 332,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 22s 217ms/step - loss: 1.1903 - acc: 0.4470\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 22s 240ms/step - loss: 0.9780 - acc: 0.5711\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 22s 240ms/step - loss: 0.8653 - acc: 0.6240\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 22s 243ms/step - loss: 0.8213 - acc: 0.6432\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 21s 237ms/step - loss: 0.7243 - acc: 0.6808\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.6551 - acc: 0.7181\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 20s 222ms/step - loss: 0.6272 - acc: 0.7192\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 20s 223ms/step - loss: 0.5315 - acc: 0.7739\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 21s 237ms/step - loss: 0.5204 - acc: 0.7774\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 22s 243ms/step - loss: 0.4775 - acc: 0.8010\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 20s 225ms/step - loss: 0.4345 - acc: 0.8261\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 20s 225ms/step - loss: 0.4193 - acc: 0.8310\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.3765 - acc: 0.8439\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.3623 - acc: 0.8495\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 20s 225ms/step - loss: 0.3510 - acc: 0.8603\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 21s 234ms/step - loss: 0.3555 - acc: 0.8533\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 20s 222ms/step - loss: 0.2796 - acc: 0.8868\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 21s 231ms/step - loss: 0.2810 - acc: 0.8864\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.2451 - acc: 0.9059\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 20s 222ms/step - loss: 0.2264 - acc: 0.9105\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.2536 - acc: 0.9031\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 20s 226ms/step - loss: 0.2305 - acc: 0.9098\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 20s 222ms/step - loss: 0.1988 - acc: 0.9268\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 0.1986 - acc: 0.9258\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 20s 225ms/step - loss: 0.1868 - acc: 0.9254\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 21s 230ms/step - loss: 0.1700 - acc: 0.9359\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 20s 225ms/step - loss: 0.1529 - acc: 0.9456\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 21s 231ms/step - loss: 0.1590 - acc: 0.9373\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 20s 223ms/step - loss: 0.1539 - acc: 0.9456\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 20s 226ms/step - loss: 0.1520 - acc: 0.9470\n",
      "13/13 [==============================] - 2s 73ms/step - loss: 2.7012 - acc: 0.6269\n",
      "Testing loss = 2.7011656761169434, Testing accuracy = 0.6269035339355469\n"
     ]
    }
   ],
   "source": [
    "train_ds_unbatched = tf.keras.utils.image_dataset_from_directory(train_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=2870, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "test_ds_unbatched = tf.keras.utils.image_dataset_from_directory(test_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=394, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "print(f'train_ds_unbatched len = {len(train_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(f'test_ds_unbatched len = {len(test_ds_unbatched)}') # 1 batch = full dataset\n",
    "print(train_ds_unbatched.class_names)\n",
    "print(test_ds_unbatched.class_names)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds_unbatched = train_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds_unbatched = test_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "x_train = None; y_train = None\n",
    "for images, labels in train_ds_unbatched:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "x_test = None; y_test = None\n",
    "for images, labels in test_ds_unbatched:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "\n",
    "size_lstm = 128\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0015\n",
    "\n",
    "#inputs = tf.keras.layers.Input(batch_input_shape=(None,256,256))\n",
    "#x = tf.keras.layers.LSTM(size_lstm)(inputs)\n",
    "#outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "#model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(batch_input_shape=(None,256,256)))\n",
    "model.add(tf.keras.layers.LSTM(size_lstm, return_sequences=True))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(size_lstm))\n",
    "model.add(tf.keras.layers.Dropout(0.01))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.01))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(#optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(tf.squeeze(x_train), tf.squeeze(y_train), epochs=num_epochs)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343e41c",
   "metadata": {},
   "source": [
    "above: size_lstm = 128\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0015\n",
    "\n",
    "Epoch 30/30\n",
    "90/90 [==============================] - 20s 226ms/step - loss: 0.1520 - acc: 0.9470\n",
    "13/13 [==============================] - 2s 73ms/step - loss: 2.7012 - acc: 0.6269\n",
    "Testing loss = 2.7011656761169434, Testing accuracy = 0.6269035339355469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971e63fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 10)      100       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 128, 128, 10)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 10)      910       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 64, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 32, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10240)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                819280    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 324       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 821,524\n",
      "Trainable params: 821,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 23s 254ms/step - loss: 0.8658 - acc: 0.6373\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 24s 271ms/step - loss: 0.4550 - acc: 0.8150\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 25s 273ms/step - loss: 0.2477 - acc: 0.9035\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 24s 265ms/step - loss: 0.1485 - acc: 0.9460\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 23s 253ms/step - loss: 0.0972 - acc: 0.9606\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 22s 244ms/step - loss: 0.0351 - acc: 0.9895\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 22s 246ms/step - loss: 0.0390 - acc: 0.9902\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 22s 243ms/step - loss: 0.0498 - acc: 0.9833\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 22s 248ms/step - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 22s 241ms/step - loss: 0.0180 - acc: 0.9962\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 22s 241ms/step - loss: 0.0165 - acc: 0.9965\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 22s 243ms/step - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 22s 243ms/step - loss: 4.7510e-04 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 23s 257ms/step - loss: 2.5515e-04 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 23s 260ms/step - loss: 1.9045e-04 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 25s 274ms/step - loss: 1.5820e-04 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 23s 254ms/step - loss: 1.3253e-04 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 22s 244ms/step - loss: 1.1344e-04 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 21s 238ms/step - loss: 9.9179e-05 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 22s 242ms/step - loss: 8.7732e-05 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 23s 260ms/step - loss: 7.8125e-05 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 23s 256ms/step - loss: 6.9927e-05 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 24s 262ms/step - loss: 6.2974e-05 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 23s 259ms/step - loss: 5.6774e-05 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 25s 274ms/step - loss: 5.1736e-05 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 24s 267ms/step - loss: 4.7013e-05 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 24s 269ms/step - loss: 4.2993e-05 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 24s 261ms/step - loss: 3.9439e-05 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 24s 267ms/step - loss: 3.6117e-05 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 22s 245ms/step - loss: 3.3341e-05 - acc: 1.0000\n",
      "13/13 [==============================] - 1s 76ms/step - loss: 5.8118 - acc: 0.7690\n",
      "Testing loss = 5.811763763427734, Testing accuracy = 0.7690355181694031\n"
     ]
    }
   ],
   "source": [
    "train_ds_unbatched = tf.keras.utils.image_dataset_from_directory(train_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=2870, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "test_ds_unbatched = tf.keras.utils.image_dataset_from_directory(test_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=394, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds_unbatched = train_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds_unbatched = test_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "x_train = None; y_train = None\n",
    "for images, labels in train_ds_unbatched:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "x_test = None; y_test = None\n",
    "for images, labels in test_ds_unbatched:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "\n",
    "size_lstm = 128\n",
    "num_epochs = 30\n",
    "learning_rate = 0.002\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(batch_input_shape=(None,256,256,1)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(80, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#model.add(tf.keras.layers.Input(batch_input_shape=(None,256,256)))\n",
    "#model.add(tf.keras.layers.LSTM(size_lstm, return_sequences=True))\n",
    "\n",
    "#model.add(tf.keras.layers.LSTM(size_lstm))\n",
    "#model.add(tf.keras.layers.Dropout(0.01))\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.01))\n",
    "#model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(#optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=num_epochs)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbf632",
   "metadata": {},
   "source": [
    "Epoch 30/30\n",
    "90/90 [==============================] - 22s 245ms/step - loss: 3.3341e-05 - acc: 1.0000\n",
    "13/13 [==============================] - 1s 76ms/step - loss: 5.8118 - acc: 0.7690\n",
    "Testing loss = 5.811763763427734, Testing accuracy = 0.7690355181694031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1b706db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 256, 1, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 256, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 946, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 935, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 928, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 841, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"sequential_14\" (type Sequential).\n    \n    Input 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 10240, but received input with shape (None, 320)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 256, 1), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d1/rr73p9ls7klcgxky01n9171m0000gn/T/ipykernel_22462/2178696168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m              metrics=['acc'])\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 946, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 935, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 928, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/training.py\", line 841, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hyeyeonhwang/Desktop/CSCI_2470/final_project/neuroDet_env/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"sequential_14\" (type Sequential).\n    \n    Input 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 10240, but received input with shape (None, 320)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 256, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "train_ds_unbatched = tf.keras.utils.image_dataset_from_directory(train_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=2870, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "test_ds_unbatched = tf.keras.utils.image_dataset_from_directory(test_dir, seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=394, color_mode = 'grayscale', shuffle=True)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds_unbatched = train_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds_unbatched = test_ds_unbatched.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "x_train = None; y_train = None\n",
    "for images, labels in train_ds_unbatched:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "x_test = None; y_test = None\n",
    "for images, labels in test_ds_unbatched:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "\n",
    "\n",
    "size_lstm = 128\n",
    "num_epochs = 10\n",
    "learning_rate = 0.002\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.Input(batch_input_shape=(None,256,256,1)))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(padding=\"same\"))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(80, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.TimeDistributed(cnn))\n",
    "\n",
    "#model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Input(batch_input_shape=(None,256,256,1))))\n",
    "#model.add(TimeDistributed(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.MaxPooling2D(padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.MaxPooling2D(padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.Conv2D(filters=10, kernel_size=3, padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.MaxPooling2D(padding=\"same\")))\n",
    "#model.add(TimeDistributed(tf.keras.layers.Flatten()))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(size_lstm))\n",
    "model.add(tf.keras.layers.Dense(80, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#model.add(tf.keras.layers.Input(batch_input_shape=(None,256,256)))\n",
    "#model.add(tf.keras.layers.LSTM(size_lstm, return_sequences=True))\n",
    "\n",
    "#model.add(tf.keras.layers.LSTM(size_lstm))\n",
    "#model.add(tf.keras.layers.Dropout(0.01))\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.01))\n",
    "#model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(#optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=num_epochs)\n",
    "model.summary()\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74f531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
