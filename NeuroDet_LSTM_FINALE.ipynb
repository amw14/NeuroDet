{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee680326",
   "metadata": {},
   "source": [
    "## NeuroDet: LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b06600",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6730f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "# Disabling GPU for the moment because of the lack of the memory\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3727d09",
   "metadata": {},
   "source": [
    "### Loading the dataset of Brain Scan images\n",
    "#### Full data for training and testing\n",
    "Source of the Dataset: [Kaggle-Brain Tumor Classification](https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri?select=Testing)<br>\n",
    "Reference for operations performed : [Tensorflow tutorial: Load Images](https://www.tensorflow.org/tutorials/load_data/images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb78c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train examples: 2870\n",
      "Total number of test examples: 394\n",
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "Found 2870 files belonging to 2 classes.\n",
      "Found 394 files belonging to 2 classes.\n",
      "['no_tumor', 'tumor']\n",
      "['no_tumor', 'tumor']\n"
     ]
    }
   ],
   "source": [
    "categories_path = {'glioma_tumor': '/glioma_tumor', 'meningioma_tumor': '/meningioma_tumor', \n",
    "                   'pituitary_tumor': '/pituitary_tumor', 'no_tumor':'/no_tumor'}\n",
    "train_path = 'BrainMRI/Training'\n",
    "test_path = 'BrainMRI/Testing'\n",
    "\n",
    "# train_glioma_dir = pathlib.Path(train_path + categories_path['glioma_tumor'])\n",
    "train_dir = pathlib.Path(train_path)\n",
    "test_dir = pathlib.Path(test_path)\n",
    "\n",
    "# Training data: number of examples\n",
    "# label = 0 | glioma_tumor: 826\n",
    "# label = 1 | meningioma_tumor: 822\n",
    "# label = 2 | no_tumor: 395 \n",
    "# label = 3 | pituitary_tumor: 827 \n",
    "\n",
    "# Testing data: number of examples\n",
    "# label = 0 | glioma_tumor: 100\n",
    "# label = 1 | meningioma_tumor: 115\n",
    "# label = 2 | no_tumor: 105\n",
    "# label = 3 | pituitary_tumor: 74\n",
    "\n",
    "num_train_examples_dict = {\n",
    "    \"label_0\": 826, \"label_1\": 822, \"label_2\": 395, \"label_3\": 827}\n",
    "\n",
    "num_test_examples_dict = {\n",
    "    \"label_0\": 100, \"label_1\": 115, \"label_2\": 105, \"label_3\": 74}\n",
    "\n",
    "\n",
    "num_train_examples = sum(num_train_examples_dict.values()) # 2870\n",
    "num_test_examples = sum(num_test_examples_dict.values()) # 394\n",
    "\n",
    "print(f'Total number of train examples: {num_train_examples}')\n",
    "print(f'Total number of test examples: {num_test_examples}') \n",
    "\n",
    "# Defining the parameters of the dataset\n",
    "img_height = 256\n",
    "img_width = 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4f259",
   "metadata": {},
   "source": [
    "#### 4-Class Classification Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train dataset using keras.utils.image_dataset_from_directory\n",
    "# To use this method, please ensure you have tf.nigthly installed \n",
    "\n",
    "train_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_train_examples, \n",
    "    shuffle=True,\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "test_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_test_examples, \n",
    "    shuffle=True,\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "print(train_data_full.class_names)\n",
    "print(test_data_full.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec8988",
   "metadata": {},
   "source": [
    "#### 2-Class Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_path = 'BrainMRI_2Class/Training'\n",
    "test2_path = 'BrainMRI_2Class/Testing'\n",
    "\n",
    "train2_dir = pathlib.Path(train2_path)\n",
    "test2_dir = pathlib.Path(test2_path)\n",
    "\n",
    "train2_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    train2_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_train_examples, \n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "test2_data_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    test2_dir, seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=num_test_examples, \n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "print(train2_data_full.class_names)\n",
    "print(test2_data_full.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278c301",
   "metadata": {},
   "source": [
    "### Normalizing the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0fc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_data_full = train_data_full.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_data_full = test_data_full.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "train2_data_full = train2_data_full.map(lambda x, y: (normalization_layer(x), y))\n",
    "test2_data_full = test2_data_full.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3c646",
   "metadata": {},
   "source": [
    "### Separate into images and labels for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ed79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_data_full:\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "    \n",
    "for images, labels in test_data_full:\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "    \n",
    "for images, labels in train2_data_full:\n",
    "    x_train2 = images\n",
    "    y_train2 = labels\n",
    "    \n",
    "for images, labels in test2_data_full:\n",
    "    x_test2 = images\n",
    "    y_test2 = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ce121",
   "metadata": {},
   "source": [
    "# 4 Class LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lstm1_size = 128\n",
    "num_epochs = 30\n",
    "learning_rate = 0.006\n",
    "dense1_size = 80\n",
    "dense2_size = 4\n",
    "dropout_rate = 0.2\n",
    "\n",
    "\n",
    "# LSTM model\n",
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(tf.keras.layers.Input(batch_input_shape=(None,img_height,img_width)))\n",
    "lstm_model.add(tf.keras.layers.LSTM(lstm1_size))\n",
    "lstm_model.add(tf.keras.layers.Dense(dense1_size, activation='relu'))\n",
    "lstm_model.add(tf.keras.layers.Dense(dense2_size, activation='softmax'))\n",
    "\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(\n",
    "    tf.squeeze(x_train), \n",
    "    tf.squeeze(y_train), \n",
    "    epochs=num_epochs)\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "test_loss, test_accuracy = lstm_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3e0a5",
   "metadata": {},
   "source": [
    "# 2 Class LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd2a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 31s 302ms/step - loss: 0.3411 - accuracy: 0.8679\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 27s 301ms/step - loss: 0.2422 - accuracy: 0.8920\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.2004 - accuracy: 0.9094\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.1712 - accuracy: 0.9261\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.1407 - accuracy: 0.9432\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 28s 307ms/step - loss: 0.1329 - accuracy: 0.9425\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 28s 312ms/step - loss: 0.1170 - accuracy: 0.9495\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 27s 299ms/step - loss: 0.1198 - accuracy: 0.9474\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 28s 306ms/step - loss: 0.1056 - accuracy: 0.9564\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.1027 - accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.0992 - accuracy: 0.9575\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.0991 - accuracy: 0.9571\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.0932 - accuracy: 0.9571\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 28s 306ms/step - loss: 0.0861 - accuracy: 0.9662\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 28s 309ms/step - loss: 0.0887 - accuracy: 0.9603\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.0832 - accuracy: 0.9672\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0839 - accuracy: 0.9631\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 28s 307ms/step - loss: 0.0710 - accuracy: 0.9728\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 28s 309ms/step - loss: 0.0705 - accuracy: 0.9732\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.0670 - accuracy: 0.9718\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,672\n",
      "Trainable params: 203,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 2s 111ms/step - loss: 0.5114 - accuracy: 0.8173\n",
      "Testing loss = 0.511426568031311, Testing accuracy = 0.817258894443512\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "lstm1_size = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 0.005\n",
    "dense1_size = 50\n",
    "dense2_size = 2\n",
    "\n",
    "\n",
    "# LSTM model\n",
    "lstm_model = tf.keras.Sequential()\n",
    "lstm_model.add(tf.keras.layers.Input(batch_input_shape=(None,img_height,img_width)))\n",
    "lstm_model.add(tf.keras.layers.LSTM(lstm1_size))\n",
    "lstm_model.add(tf.keras.layers.Dense(dense1_size, activation='relu'))\n",
    "lstm_model.add(tf.keras.layers.Dense(dense2_size, activation='softmax'))\n",
    "\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(\n",
    "    tf.squeeze(x_train2), \n",
    "    tf.squeeze(y_train2), \n",
    "    epochs=num_epochs)\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "test_loss, test_accuracy = lstm_model.evaluate(x_test2, y_test2)\n",
    "\n",
    "print(f'Testing loss = {test_loss}, Testing accuracy = {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroDet_env",
   "language": "python",
   "name": "neurodet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
